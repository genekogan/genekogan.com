<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">

<html lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta http-equiv="Description" content="Writings by Gene Kogan" />
	<meta name="author" content="Gene Kogan">
	<title>Writing | Gene Kogan | Gene Kogan</title>
	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://www.genekogan.com/rss/rss2.xml" />
	<link href="/css/style.css" rel="stylesheet" type="text/css" />
	<link href="/css/lightbox.css" rel="stylesheet" />
	<script type="text/javascript" src="/js/jquery-1.7.2.min.js"></script>
	<script type="text/javascript" src="/js/lightbox.js"></script>

</head>
<body>
	<div id="container">
		<div id="header">
			<div id="name">
				<h1><a href="/" >Gene Kogan</a></h1>
			</div>
			<div id="menucontainer">
				<div id="menudiv">
					<ul id="menu">
						<li><a href="/" >Works</a></li>
						<li><a href="/writing/" class="current">Writing</a></li>
						<li><a href="/about.html" >About</a></li>
						<li><a href="/rss/rss2.xml" ><img src="/images/misc/rss.jpg" alt="RSS" /></a></li>
					</ul>
				</div>
				<div id="socialdiv">
					<ul id="social">
						<li><a href="http://www.flickr.com/photos/genekogan/"><img src="/images/misc/icon_flickr.png" alt="Flickr" /></a></li>
						<li><a href="http://www.vimeo.com/genekogan"><img src="/images/misc/icon_vimeo.png" alt="Vimeo" /></a></li>
						<li><a href="http://www.soundcloud.com/genekogan"><img src="/images/misc/icon_soundcloud.png" alt="SoundCloud" /></a></li>
						<li><a href="http://www.github.com/genekogan"><img src="/images/misc/icon_github.png" alt="GitHub" /></a></li>
						<li><a href="http://www.openprocessing.org/user/19808"><img src="/images/misc/icon_openprocessing.png" alt="OpenProcessing" /></a></li>
						<li><a href="http://www.twitter.com/genekogan"><img src="/images/misc/icon_twitter.png" alt="Twitter" /></a></li>
					</ul>
				</div>
			</div>
		</div>
		<div id="main">
						<h5>25 Sep 2012</h5>

						<h1><a href="/writing/intro-to-logger.html">Logger</a></h1>

			
			<p>
				In the days before I moved to India, I wrote a lightweight piece of software I've been calling logger, which serves as a sort of quick entry electronic journal which I use, in the broadest sense, to record my life. The notes range from mundane records of the things I do everyday to wry observations about life here to momentary ideas I have for projects to technical questions and notes-to-self. A quick keyboard shortcut lets me pull up a text field to add an entry, as seen below. The project is mostly a personal one, maybe the most personal I've done, though I have <a href="https://github.com/genekogan/Logger">published the code on Github</a>.
			</p>
			<p>
				<center>
				<img src="/images/writing/logger-entry.jpg" />
				</center>
			</p>
			<p>
				After I submit the text, it is augmented with a timestamp and my geolocation data at that moment, and added to the growing database of entries. The location data is gathered with a Python script I wrote which determines my precise latitude and longitude by triangulating the locations of nearby wireless access points using Google Maps API, a method suggested to me by my friend John Gallagher who works at <a href="http://www.foursquare.com">FourSquare</a>, a mobile app which handles geolocation in a similar way, as do Google and many others. The short code snippet for this can also be found <a href="http://www.github.com/genekogan/wifi_geolocation">on my Github</a>.
			</p>
			<p>
				Additionally, I'm reserving special characters in the logs to track particular objects over time. Names of people are prefixed with <i>~</i>, locations prefixed by a <i>@</i>, tags/projects/misc by a <i>#</i>, ideas by a <i>!</i>, and questions by a <i>?</i>. As in Twitter, these characters will make it possible to isolate subjects of interest to me. Given the integration of very fine-grained geolocation, I am also able to track and cross-reference location as well.
			</p>
			<p>
				The last noteworthy feature is its accessibility through the OSX app <a href="http://www.alfredapp.com/">Alfred</a>, which is a Spotlight replacement that lets you run scripts. This makes it very quick and easy to add an entry.
			</p>	
			<p>
				This project has basically three objectives. The first is to preserve those memories which inevitably dissolve over time. It's not so much a fear of forgetting, because even an obscure memory can be quickly dusted off if evoked by some clue. I think memories are sort of like trinkets buried in the back of your closet; you'd recognize one if it were presented to you, but when is the next time you are going to happen to look over there? That must be why people keep diaries and journals, something I never really did much of.
			</p>
			<p>
				The second motivation, and far geekier one, is for self-analysis. That aspect is greatly influenced by <a href="http://bits.blogs.nytimes.com/2010/02/09/an-annual-report-on-one-mans-life/">Nicholas Felton</a> whose annual report on his year neatly deconstructs even the most esoteric components of his life. It's mostly curiosity, but I think data can tell a story that I wouldn't otherwise notice because of ignorance or forgetfulness, and most interesting of all, bias. Interesting the human mind's tendency towards self-deceit, <a href="http://www.sciencedaily.com/releases/2012/09/120906123324.htm?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+sciencedaily%2Fscience_society+%28ScienceDaily%3A+Science+%26+Society+News%29">"hindsight bias"</a>, to justify and revise history as probably some evolutionary self-defense mechanism to keep sanity. Time distorts recollection, and by forcing myself to write it down, I'm more likely to confront trails of thought I'm otherwise likely to forget or suppress ("that idea really went nowhere did it?") and less likely to lie about them ("i never really thought it was a good idea to begin with...")
			</p>
			<p>
				At the moment, I've stopped developing the software and am leaving the analytical part for sometime in the future; for now I am simply using it to log and build up a database worth mining later. I've made around 1200 entries so far in six weeks, and expect I may have over 10,000 if I keep the habit up over a year.
			</p>
			<p>
				Some important questions remain to be answered. To what extent are the results of the project publicized? Are these to remain my private records, or do I practice "radical openness" and just keep the raw notes publicly accessible, forfeiting my privacy like Ai Weiwei? What's the difference between total secrecy and total transparency? Not much probably -- it's those in-between circumstances where some parties have access to the data to which others do not where the discrepancies begin to have the most pronounced effect. I'm not too concerned for now, but these are issues to resolve in the future.
			</p>
			<p/><p/><hr width="90%" align="center"><p/>
						<h5>7 Sep 2012</h5>

						<h1><a href="/writing/field-rec-navigator.html">Visualizing my field recordings</a></h1>

			
			<p>
				<img src="http://genekogan.com/images/xinjiang-hunza/thumb_xinjiang-hunza-compilation-2.jpg" style="float:right;">
				I'm beginning to work on a project which I've been tossing around for the last few weeks, which involves visualizing and navigating through my field recordings. I've had an interest in field recording for the past few years, and have incorporated it into a few projects in the past: see <a href="http://www.alongthekarakoram.com">Along the Karakoram</a>, <a href="http://genekogan.com/works/xinjiang-hunza-compilation.html">Xinjiang-Hunza compilation</a>, <a href="http://turbulence.org/soundtransit/search/artistinfo.php?id=473">Sound Transit</a>, and <a href="http://soundcloud.com/genekogan/stone-barns">Stone Barns recording</a>. 
			</p>
			<p>
				<iframe width="20%" height="166" scrolling="no" frameborder="no" src="http://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F51667833&amp;auto_play=false&amp;show_artwork=false&amp;color=23521d" style="float:left;"></iframe>
				I am inclined towards field recording by interests in recollection and documentation through sound, i.e. <a href="http://www.phonography.org/word.htm">"phonography"</a>, sound ecology (e.g. <a href="http://en.wikipedia.org/wiki/R._Murray_Schafer">R. Murray Schafer</a>, <a href="http://www.sfu.ca/~westerka/">Hildegard Westerkamp</a>), and sound art/musique concrète (e.g. <a href="http://www.michelchion.com/v1/">Michel Chion</a>, <a href="http://www.chriswatson.net">Chris Watson</a>, <a href="http://www.franciscolopez.net">Francisco López</a>). Like the latter two, I am interested in sound design, finding complementary and contrasting sounds from the real world, and using them as a palette for composition. My recorder has collected samples from bazaars, alleys, malls, protests, temples, forests, elevator shafts, pig pens, and various other locations which occasionally draw funny looks from people or animals.
			</p>
			<p>
				Because I compile many hours of recordings, I can gain some agility in managing my collection via audio processing techniques to help organize those sounds along various parameters of interest, and find clusters of similar sounds and complementary sound pairs. I am aided here by <a href="https://www.jyu.fi/hum/laitokset/musiikki/en/research/coe/materials/mirtoolbox">MIRtoolbox</a>, a MATLAB-based library for <a href="http://en.wikipedia.org/wiki/Music_information_retrieval">music information retrieval</a>, made by a group at the University of Jyväskylä in Finland. MIRtoolbox fluidly handles a number of common audio tasks. With it I automatically segmented the raw recordings into a collection of relatively self-contained sound events ranging from half a second  to  more than 10 seconds long. The segmentation algorithm attempts to optimally divide each recording to maximize the dissimilarity among all segment pairs, example shown below.
			</p>
				<center>
				<a href="../images/writing/audio-segmentation.jpg" rel="lightbox[fieldrecnav]"><img src="../images/writing/thumb_audio-segmentation.jpg" /></a>
				</center>
			<p>
				I then extract features from the segments, which are various quantities characterizing the dynamics and timbre of the sound, providing for a compact representation of each segment, with similar groups of sounds having relatively similar representations (ideally). Some of those features are shown below: spectral flux is a measure of the dispersion of the sound among all frequency bands (loosely related to the "noisiness" of the sound), roughness can be interpreted as a measure of dissonance in the signal, brightness is a measure of how much of the sound's energy is contained in frequencies above 1500 Hz, and RMS (root mean squared) energy corresponds to the average energy level, correlating to loudness.
			</p>
			<p>
				<center>
				<a href="../images/writing/audio-features.jpg" rel="lightbox[fieldrecnav]"><img src="../images/writing/thumb_audio-features.jpg" /></a>
				</center>
			</p>
			<p>
				The resulting high-dimensional matrix describing all these segments is then finally reduced to a three-dimensional one via <a href="http://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a>. I can then plot the audio segments in a three-dimensional view, as seen below. The colors refer to different source audio files, and not surprisingly, segments from within the same file tend to cluster together. But there is some overlap among sounds contained in different files, and its these pairs where I hope to find unexpectedly nice juxtapositions.
			</p>
			<p>
				<center>
				<a href="../images/writing/field-rec-3d.jpg" rel="lightbox[fieldrecnav]"><img src="../images/writing/thumb_field-rec-3d.jpg" /></a>
				</center>
			</p>
			<p>
				I'm using <a href="http://supercollider.sourceforge.net/">SuperCollider</a> to handle the audio playback; meanwhile Processing runs the visual and interactive component, and communicates with SuperCollider via open sound control (OSC).  My goal is to create a high-level interface that lets me effectively navigate through all this audio content, and slowly incorporate musical elements into it, building towards a sort of musical instrument with typical features like loops and filters. I will post more later when I am closer to having something of a demo.
			</p>
			<p/><p/><hr width="90%" align="center"><p/>
		</div>
	</div>

	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-33352395-1']);
		_gaq.push(['_trackPageview']);
		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>

</body>
</html>
